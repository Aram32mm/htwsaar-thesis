\chapter{Conclusion}
\label{ch:conclusion}

This thesis presented a hybrid retrieval system for payment validation rules, demonstrating that practical information retrieval can be achieved within banking infrastructure constraints. We developed, implemented, and evaluated a system that combines semantic embeddings, keyword matching, and string similarity to help quality assurance teams and developers find relevant rules quickly and accurately.

\section{Summary of Contributions}

\subsection{Technical Implementation}

We built a retrieval system achieving 48.2\% MRR@5 through weighted combination of three signals: semantic similarity (80\%), BM25 keyword matching (10\%), and fuzzy string matching (10\%). These weights, discovered through Leave-One-Out Cross-Validation on 30 test queries, improved performance by 4.8 percentage points (11\% relative improvement) over initial configurations. The system operates with median query latency of 58ms and uses 530MB of memory to serve 1,157 validation rules.

The implementation uses standard Python libraries—Dash for the web interface, scikit-learn for similarity computation, and SQLite for data management—avoiding external dependencies that would complicate deployment in regulated environments. All embeddings are pre-computed offline and stored as JSON strings in a CSV file, enabling single-file deployment while maintaining acceptable startup times (464ms).

\subsection{Data Standardization}

A significant portion of our work involved consolidating scattered rule documentation into a standardized CSV format with consistent field definitions. This process included:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Mapping heterogeneous rule formats to a unified schema
  \item Generating enhanced descriptions using Gemini-2.5-Pro (offline only)
  \item Computing 1024-dimensional embeddings with UAE-Large-V1
  \item Establishing sustainable update procedures
\end{itemize}

The resulting corpus serves as the single source of truth for validation rules, replacing multiple inconsistent documentation sources.

\subsection{Evaluation Methodology}

We implemented Leave-One-Out Cross-Validation to tune weights while avoiding overfitting on our limited test set. The evaluation measured multiple metrics (MRR@5, Hit@1/3/5, Coverage) and included ablation studies confirming that each signal contributes to performance. Sensitivity analysis showed the system remains stable with ±10\% weight variations, important for production deployment where exact tuning may drift.

\section{Design Trade-offs and Lessons}

\subsection{Architectural Decisions}

Our monolithic architecture—running everything in a single Python process—was initially driven by deployment constraints but proved advantageous for our use case:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Eliminated network latency between components
  \item Simplified debugging and monitoring
  \item Reduced deployment complexity to a single container
  \item Ensured deterministic behavior for audit compliance
\end{itemize}

For our scale (1,157 rules, 10-20 concurrent users), the monolithic approach outperforms a distributed architecture in both performance and maintainability.

\subsection{Technology Choices}

Several seemingly suboptimal choices proved correct for our context:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item \textbf{CSV over database}: Enables version control and manual inspection
  \item \textbf{JSON string embeddings}: Maintains single-file deployment
  \item \textbf{Brute-force search}: More reliable than approximate methods at our scale
  \item \textbf{No FAISS}: Reduced complexity without performance penalty
\end{itemize}

These decisions reflect a principle of using the simplest tool that meets requirements rather than the most sophisticated available.

\section{Limitations}

\subsection{Current Constraints}

The system has clear boundaries that should be acknowledged:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item \textbf{Scale limit}: Performance degrades beyond ~10,000 rules due to linear search
  \item \textbf{Evaluation dataset}: 30 queries insufficient for statistical significance
  \item \textbf{Language coverage}: Primarily English, limited German support
  \item \textbf{Query understanding}: No handling of acronyms, typos, or implicit context
  \item \textbf{Update frequency}: Requires restart for corpus changes
\end{itemize}

\subsection{Known Failure Modes}

The system struggles with certain query types:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Queries mixing multiple languages
  \item Temporal references ("rules added last month")
  \item Implicit organizational context ("our limit" without specifying which)
  \item Highly technical abbreviations not in training data
\end{itemize}

These limitations are acceptable for initial deployment but should be addressed based on user feedback.

\section{Future Work}

\subsection{Near-term Improvements (3-6 months)}

Based on the current implementation, practical enhancements include:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item \textbf{Expanded evaluation}: Collect 200+ queries from actual usage logs
  \item \textbf{Query logging}: Track searches to understand real user needs
  \item \textbf{Caching layer}: Store frequent queries to reduce computation
  \item \textbf{Binary indices}: Serialize indices to reduce startup time
  \item \textbf{Error handling}: Improve resilience to malformed queries
\end{itemize}

\subsection{Medium-term Extensions (6-12 months)}

With proven usage, the system could be enhanced with:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item \textbf{Relevance feedback}: Use click-through data to improve ranking
  \item \textbf{Multi-lingual support}: Proper German embeddings and query handling
  \item \textbf{API endpoints}: Enable integration with other internal tools
  \item \textbf{Incremental updates}: Add new rules without full restart
  \item \textbf{Usage analytics}: Dashboard showing common queries and success rates
\end{itemize}

\subsection{Potential Research Directions}

Longer-term research could explore:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Learning-to-rank models trained on user interactions
  \item Cross-encoder reranking for top candidates
  \item Query expansion using domain-specific synonyms
  \item Federated learning across multiple banks (respecting privacy)
  \item Conversational interfaces for iterative refinement
\end{itemize}

However, these should only be pursued if simpler approaches prove insufficient.

\section{Practical Impact}

\subsection{Deployment Readiness}

The system is ready for production deployment with:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Documented deployment procedures
  \item Performance meeting all specified targets
  \item Graceful degradation for edge cases
  \item Audit trail compliance built-in
  \item Maintenance procedures established
\end{itemize}

Initial deployment should be to a pilot group for feedback collection before wider rollout.

\subsection{Expected Benefits}

Based on preliminary testing, we expect the system to:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Reduce rule discovery time to seconds
  \item Decrease incorrect rule application through better search
  \item Improve onboarding for new developers
  \item Standardize rule documentation practices
  \item Provide metrics on rule usage patterns
\end{itemize}

These benefits should be measured post-deployment to validate the system's value.

\section{Concluding Remarks}

This thesis demonstrated that effective information retrieval for specialized domains can be achieved through pragmatic engineering rather than complex architectures. By combining three complementary retrieval signals, standardizing scattered documentation, and implementing rigorous evaluation, we built a system that meets real user needs within strict operational constraints.

The key insight is that banking IT environments, with their seemingly restrictive requirements, actually benefit from simpler architectures. Our monolithic design, CSV-based storage, and standard library implementation prove more maintainable than distributed alternatives while delivering comparable performance.

The success of this project lies not in novel algorithms or cutting-edge models, but in careful engineering of proven techniques. We showed that semantic search enhances but doesn't replace keyword matching, that proper data standardization is as important as retrieval algorithms, and that comprehensive evaluation on even small datasets provides valuable insights.

As financial institutions face growing regulatory complexity, tools for efficient rule discovery become critical infrastructure. Our system provides a foundation for this capability, with clear paths for enhancement based on actual usage patterns rather than speculative requirements.

The hybrid retrieval system is now ready to help Deutsche Bank's developers and QA teams find the validation rules they need quickly and accurately. Its successful deployment will validate our approach of combining modern NLP with pragmatic engineering to solve real problems within real constraints.
