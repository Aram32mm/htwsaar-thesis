\chapter{Implementation}
\label{ch:implementation}

This chapter details the Python implementation of our hybrid retrieval system, describing the codebase structure, component organization, and key design choices that enable efficient operation without external dependencies. We present the practical implementation decisions and trade-offs made to achieve a working system within project constraints.

\section{Project Structure}

The codebase is organized into logical modules separating UI components from retrieval logic:

\begin{lstlisting}[language=bash, caption={Project directory structure}, label={lst:project-structure}]
validation-rule-search/
├── app.py                  # Main Dash application entry point
├── config.py              # Configuration settings
├── requirements.txt       # Python dependencies
├── data/
│   └── rules_corpus.csv  # Standardized CSV corpus
├── components/
│   ├── __init__.py
│   ├── generator.py      # Chat interface and rule generation UI
│   ├── search.py         # Search interface with filters
│   └── layout.py         # Unified interface combining both
├── rag/
│   ├── __init__.py
│   ├── rule_retriever.py # Main retrieval orchestration
│   ├── rule_data_loader.py # CSV corpus loading
│   ├── embedding_manager.py # Embedding operations
│   └── embedding_index.py # Semantic search index
├── db/
│   ├── rules.db          # SQLite database (generated)
│   └── db_manager.py     # Database operations
└── notebooks/
   └── evaluation.ipynb  # LOOCV experiments
\end{lstlisting}

\section{Core Dependencies}

The system relies on established Python libraries to minimize complexity:

\begin{table}[ht]
\centering
\begin{tabular}{lll}
\toprule
\textbf{Library} & \textbf{Version} & \textbf{Purpose} \\
\midrule
dash & 2.14.0 & Web application framework \\
pandas & 2.0.3 & CSV processing \\
numpy & 1.24.3 & Numerical operations \\
scikit-learn & 1.3.0 & Cosine similarity computation \\
rank-bm25 & 0.2.2 & BM25 implementation \\
fuzzywuzzy & 0.18.0 & Fuzzy string matching \\
sqlite3 & (stdlib) & Database operations \\
json & (stdlib) & Embedding parsing \\
\bottomrule
\end{tabular}
\caption{Python dependencies used in the implementation.}
\label{tab:dependencies}
\end{table}

\section{User Interface Components}

The UI layer consists of three main components that communicate through Dash callbacks:

\subsection{Search Component}

The search component handles the primary retrieval interface:

\begin{lstlisting}[language=Python, caption={Search component structure}, label={lst:search-component}]
# components/search.py placeholder
# Key elements:
# - Search input bar with query handling
# - Mode selector (Keyword vs Hybrid)
# - Facet filters for Rule Type, Country, etc.
# - Results display with rule cards
# - Score visualization
\end{lstlisting}

\begin{figure}[ht]
\centering
\fbox{\parbox{0.9\textwidth}{\centering\vspace{3cm}\textit{[Screenshot placeholder: Search interface showing query bar, filters, and ranked results with rule cards displaying badges and scores]}\vspace{3cm}}}
\caption{Search component interface with faceted filtering and result display.}
\label{fig:search-interface}
\end{figure}

\subsection{Generator Component}

The generator component provides the chat-based interface:

\begin{lstlisting}[language=Python, caption={Generator component structure}, label={lst:generator-component}]
# components/generator.py placeholder
# Key elements:
# - Chat interface for conversational search
# - Rule dropdown selector
# - Generation controls
# - Response display area
\end{lstlisting}

\begin{figure}[ht]
\centering
\fbox{\parbox{0.9\textwidth}{\centering\vspace{3cm}\textit{[Screenshot placeholder: Generator interface showing chat conversation, rule dropdown selector, and generated responses]}\vspace{3cm}}}
\caption{Generator component with chat interface and rule selection dropdown.}
\label{fig:generator-interface}
\end{figure}

\subsection{Layout Component}

The layout component unifies both interfaces into a single application:

\begin{lstlisting}[language=Python, caption={Layout component combining interfaces}, label={lst:layout-component}]
# components/layout.py placeholder
# Structure:
# - Tab or split-screen layout
# - Shared header and navigation
# - Component state management
# - Cross-component communication
\end{lstlisting}

\begin{figure}[ht]
\centering
\fbox{\parbox{0.9\textwidth}{\centering\vspace{3cm}\textit{[Screenshot placeholder: Unified interface showing both search and generator components in a tabbed or split-screen layout]}\vspace{3cm}}}
\caption{Unified layout integrating search and generator components.}
\label{fig:unified-layout}
\end{figure}

\section{RAG Implementation}

\subsection{Rule Data Loader}

The data loader handles CSV ingestion at startup:

\begin{lstlisting}[language=Python, caption={Rule data loader implementation}, label={lst:data-loader}]
# rag/rule_data_loader.py placeholder
# Responsibilities:
# - Read CSV with pandas
# - Parse embedding JSON strings
# - Validate data integrity
# - Handle missing values
# - Cache processed data
\end{lstlisting}

Key implementation considerations:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Robust handling of malformed CSV entries
 \item Graceful degradation when embeddings are invalid
 \item Memory-efficient loading for the corpus
\end{itemize}

\subsection{Embedding Manager}

The embedding manager handles vector operations:

\begin{lstlisting}[language=Python, caption={Embedding manager operations}, label={lst:embedding-manager}]
# rag/embedding_manager.py placeholder
# Functions:
# - Parse JSON embedding strings
# - L2 normalization
# - Query embedding generation (if needed)
# - Vector validation
\end{lstlisting}

\subsection{Embedding Index}

The semantic search index provides similarity search:

\begin{lstlisting}[language=Python, caption={Embedding index for semantic search}, label={lst:embedding-index}]
# rag/embedding_index.py placeholder
# Implementation:
# - Build matrix from rule embeddings
# - Cosine similarity via scikit-learn
# - Top-k retrieval
# - Score normalization
\end{lstlisting}

\subsection{Rule Retriever}

The main retriever orchestrates all search operations:

\begin{lstlisting}[language=Python, caption={Rule retriever orchestration}, label={lst:rule-retriever}]
# rag/rule_retriever.py placeholder
# Core methods:
# - search_rules(): Main entry point
# - apply_filters(): Faceted filtering
# - compute_scores(): Per-signal scoring
# - hybrid_score(): Weighted combination
# - format_results(): UI preparation
\end{lstlisting}

The retriever implements the search pipeline:
\begin{enumerate}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Accept query and filter parameters
 \item Apply facet filters to narrow candidate set
 \item Compute BM25, fuzzy, and semantic scores
 \item Normalize scores per signal
 \item Apply semantic gate threshold
 \item Combine with tuned weights
 \item Return top-k results
\end{enumerate}

\section{Database Layer}

\subsection{Database Manager}

The database manager handles SQLite operations:

\begin{lstlisting}[language=Python, caption={Database manager implementation}, label={lst:db-manager}]
# db/db_manager.py placeholder
# Capabilities:
# - Initialize SQLite database
# - Load rules from CSV
# - Execute filter queries
# - Cache query results
# - Handle concurrent access
\end{lstlisting}

The SQLite database serves primarily for:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Efficient filtering by categorical fields
 \item Metadata storage and retrieval
 \item Query result caching
\end{itemize}

Note that the actual search indices (BM25, semantic) are maintained in memory, not in SQLite.

\section{Callback Architecture}

The components communicate through Dash callbacks:

\begin{lstlisting}[language=Python, caption={Callback structure connecting UI to RAG}, label={lst:callbacks}]
# Main callback pattern
@app.callback(
   Output('results-container', 'children'),
   Input('search-input', 'value'),
   Input('search-mode', 'value'),
   State('filter-dropdowns', 'value')
)
def search_callback(query, mode, filters):
   # Invoke retriever
   # Format results
   # Return UI components
   pass
\end{lstlisting}

Key callback flows:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Search component → Rule Retriever → Results display
 \item Generator component → Rule Retriever → Chat response
 \item Filter changes → Database query → Updated results
\end{itemize}

\section{Performance Considerations}

\subsection{Memory Management}

The implementation makes practical trade-offs for memory efficiency:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Float32 embeddings reduce memory usage by half
 \item Lazy loading defers parsing until needed
 \item Shared numpy arrays avoid duplication
\end{itemize}

\subsection{Startup Optimization}

While the system requires index building at startup, several techniques minimize the impact:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Parallel index construction where possible
 \item Progress indicators for user feedback
 \item Caching of preprocessed data between restarts
\end{itemize}

\section{Implementation Challenges}

\subsection{Challenge: Balancing Simplicity and Performance}

The implementation prioritizes simplicity over optimal performance in several areas:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Brute-force cosine similarity instead of approximate methods
 \item In-memory indices rebuilt at startup
 \item Synchronous processing without parallelization
\end{itemize}

These choices reflect the project's emphasis on maintainability and the relatively small corpus size.

\subsection{Challenge: Handling Edge Cases}

Practical issues addressed during implementation:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Malformed embeddings in CSV: Skip and log warnings
 \item Empty search results: Provide helpful feedback
 \item Database locks: Implement retry logic
 \item Memory spikes: Limit candidate pool sizes
\end{itemize}

\section{Configuration Management}

System configuration is centralized for easy adjustment:

\begin{lstlisting}[language=Python, caption={Configuration structure}, label={lst:config}]
# config.py placeholder
# Settings include:
# - File paths (CSV, database)
# - Search weights (0.10, 0.10, 0.80)
# - Semantic threshold (0.30)
# - UI parameters (port, host)
# - Debug flags
\end{lstlisting}

\section{Deployment}

The application runs as a standard Python web service:

\begin{lstlisting}[language=bash, caption={Starting the application}, label={lst:deployment}]
# Simple deployment
python app.py

# With configuration
python app.py --port 8050 --host 0.0.0.0

# Production with gunicorn
gunicorn app:server --workers 4
\end{lstlisting}

\section{Testing Approach}

While formal test coverage is limited, the implementation has been validated through:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Manual testing of search scenarios
 \item Evaluation notebooks with LOOCV experiments
 \item User acceptance testing with domain experts
 \item Performance profiling under load
\end{itemize}

Future work should include comprehensive unit and integration tests to ensure reliability.

\section{Code Organization Principles}

The implementation follows practical organizing principles:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item \textbf{Separation of Concerns}: UI, retrieval, and data layers are distinct
 \item \textbf{Single Responsibility}: Each class handles one primary function
 \item \textbf{Minimal Dependencies}: Avoid complex inheritance hierarchies
 \item \textbf{Clear Interfaces}: Well-defined methods for component interaction
\end{itemize}

\section{Limitations and Future Improvements}

The current implementation has several known limitations:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item \textbf{No comprehensive test suite}: Testing relies on manual validation
 \item \textbf{Limited error recovery}: Some edge cases may cause failures
 \item \textbf{Basic caching}: More sophisticated caching could improve performance
 \item \textbf{Single-threaded processing}: Could benefit from parallelization
\end{itemize}

Despite these limitations, the system successfully demonstrates that effective retrieval can be achieved with a straightforward implementation.

\section{Summary}

The implementation takes a pragmatic approach to building a hybrid retrieval system within banking constraints. By focusing on core functionality and avoiding unnecessary complexity, we deliver a working system that meets requirements while remaining maintainable. The modular structure, with clear separation between UI components and retrieval logic, enables future enhancements without major refactoring.

Key lessons from the implementation:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Simple solutions often suffice for well-defined problems
 \item Standard libraries provide most needed functionality
 \item Clear code organization matters more than clever optimizations
 \item Practical trade-offs enable project completion within constraints
\end{itemize}

The complete implementation demonstrates that enterprise retrieval systems can be built with modest resources and conventional techniques when requirements are well understood and constraints are respected.
