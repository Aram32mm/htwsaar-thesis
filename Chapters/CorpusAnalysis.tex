\chapter{Corpus Analysis}
\label{ch:corpus-analysis}

This chapter presents a comprehensive analysis of the standardized validation rule corpus used in our retrieval system. Through systematic examination of 1,157 rules consolidated from Deutsche Bank's payment processing platform, we assess field completeness, data quality, and embedding characteristics to understand the corpus's strengths and identify areas for improvement.

\section{Data Consolidation and Enhancement}

\subsection{Multi-Source Consolidation}

The corpus was constructed by consolidating three separate CSV files from different validation subsystems, each containing partially overlapping rule sets with inconsistent formats. The consolidation process involved:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item \textbf{Source integration}: Merged 1,743 total rules from three CSV sources
 \item \textbf{Deduplication}: Identified and removed 586 duplicate rules using \texttt{rule\_name} as the unique identifier
 \item \textbf{Schema alignment}: Mapped heterogeneous field names to standardized schema
 \item \textbf{Conflict resolution}: For duplicate rules, retained the version with most complete fields
 \item \textbf{Final corpus}: 1,157 unique validation rules
\end{itemize}

\subsection{LLM-Based Field Generation}

After consolidation, we enhanced the corpus using Gemini-2.5-Pro in an offline batch process. The model received three core fields from the original data:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item \texttt{rule\_name}: The human-readable identifier
 \item \texttt{rule\_description}: Basic business description (when available)
 \item \texttt{rule\_code}: The actual Kotlin validation implementation
\end{itemize}

From these inputs, Gemini-2.5-Pro generated three enhanced fields:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item \textbf{\texttt{llm\_description}}: Comprehensive natural language description averaging 89 words, synthesizing the rule's purpose, validation logic, and business context
 \item \textbf{\texttt{keywords}}: Extracted and curated search terms relevant to the rule, averaging 11.6 keywords per rule
 \item \textbf{Categorical tags}: Scraped and structured \texttt{rule\_type}, \texttt{country}, \texttt{business\_type}, and \texttt{party\_agent} values from unstructured text
\end{itemize}

This offline enhancement process transformed sparse original data into rich, searchable content that forms the foundation of our retrieval system.

\section{Corpus Overview}
The standardized corpus comprises 1,157 validation rules consolidated from multiple distributed sources across the payment processing system. Each rule occupies a single row in our CSV format, with 15 fields capturing identifiers, descriptions, error codes, search metadata, and pre-computed embeddings. The complete dataset requires 32.21 MB of memory when loaded, making it suitable for in-memory processing on standard hardware.

\subsection{Field Structure}

The corpus employs a carefully designed schema balancing completeness with storage efficiency:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item \textbf{Core Identifiers}: \texttt{rule\_name} serves as the primary human-readable identifier
 \item \textbf{Multilingual Descriptions}: \texttt{description\_en}, \texttt{description\_de}, and \texttt{rule\_description} for business context
 \item \textbf{Error Codes}: \texttt{bansta\_error\_code} and \texttt{iso\_error\_code} for regulatory reference
 \item \textbf{Implementation}: \texttt{rule\_code} containing the actual validation logic
 \item \textbf{Search Fields}: \texttt{keywords} (curated terms) and \texttt{llm\_description} (enhanced text)
 \item \textbf{Categorical Tags}: \texttt{rule\_type}, \texttt{country}, \texttt{business\_type}, \texttt{party\_agent}
 \item \textbf{Embeddings}: 1024-dimensional vectors stored as JSON strings
\end{itemize}

\subsection{Corpus Composition}

Table~\ref{tab:corpus-composition} shows the distribution of corpus fields across functional categories.

\begin{table}[h]
\centering
\begin{tabular}{lr}
\toprule
\textbf{Field Category} & \textbf{Number of Fields} \\
\midrule
Core Identifiers & 1 \\
Descriptions & 3 \\
Error Codes & 2 \\
Search Metadata & 3 \\
Categorical Tags & 4 \\
Implementation & 1 \\
Embeddings & 1 \\
\midrule
\textbf{Total} & \textbf{15} \\
\bottomrule
\end{tabular}
\caption{Distribution of corpus fields across functional categories.}
\label{tab:corpus-composition}
\end{table}

\section{Field Completeness Analysis}

The LLM enhancement process dramatically improved field completeness, particularly for search-critical fields. While the original consolidated data had significant gaps, the Gemini-2.5-Pro generation achieved 100\% coverage for keywords and enhanced descriptions.

\subsection{Critical Field Coverage}

The analysis reveals perfect coverage in search-critical fields, as shown in Table~\ref{tab:field-completeness}. Error codes, while incomplete at approximately 50\%, are not essential for retrieval functionality and serve primarily as reference metadata.

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Field} & \textbf{Coverage (\%)} & \textbf{Status} \\
\midrule
\multicolumn{3}{l}{\textit{Search-Critical Fields (Target: 95\%)}} \\
rule\_name & 100.0 & \checkmark \\
rule\_code & 100.0 & \checkmark \\
keywords & 100.0 & \checkmark \\
embedding & 100.0 & \checkmark \\
llm\_description & 100.0 & \checkmark \\
rule\_description & 95.9 & \checkmark \\
\midrule
\multicolumn{3}{l}{\textit{Optional Reference Fields}} \\
bansta\_error\_code & 51.2 & -- \\
iso\_error\_code & 50.0 & -- \\
\bottomrule
\end{tabular}
\caption{Field completeness showing perfect coverage in all search-critical fields.}
\label{tab:field-completeness}
\end{table}

\section{Categorical Tag Analysis}

Categorical tags enable faceted search and filtering, crucial for narrowing large result sets. Tag standardization represents the highest priority for corpus improvement.

\subsection{Tag Coverage and Diversity}

Table~\ref{tab:tag-coverage} reveals significant fragmentation in categorical tags, with rule types showing 177 unique values despite covering only 73.7\% of the corpus.

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Tag Type} & \textbf{Coverage (\%)} & \textbf{Unique Values} & \textbf{Entropy (bits)} \\
\midrule
Rule Type & 73.7 & 177 & 5.00 \\
Party Agent & 63.8 & 132 & 4.13 \\
Country & 48.7 & 100 & 5.55 \\
Business Type & 36.5 & 128 & 4.28 \\
\bottomrule
\end{tabular}
\caption{Categorical tag dimensions showing coverage gaps and excessive fragmentation.}
\label{tab:tag-coverage}
\end{table}

\subsection{Tag Quality Issues}

Analysis reveals critical standardization needs:

\textbf{Rule Type Fragmentation (177 unique values):}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item ``Validation'' vs ``Validation Rule'' (360 rules affected) -- should be unified
 \item ``Data Enrichment'' vs ``Data Population'' (87 rules) -- unclear distinction
 \item 42 singleton values that should map to standard categories
 \item \textbf{Recommendation}: Reduce to 15-20 standardized types
\end{itemize}

\textbf{Country Coverage Gaps (48.7\% coverage):}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item 594 rules without country tags likely have geographic scope
 \item ISO country codes mixed with full names (needs ISO 3166 standardization)
 \item ``Global'' tag needed for universally applicable rules
\end{itemize}

\textbf{Business Type Under-specification (36.5\% coverage):}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item ``Payments'' too generic (214 rules need sub-categorization)
 \item 735 rules without business type severely limit filtering
 \item Overlapping categories need clear boundaries
\end{itemize}

\textbf{Party Agent Ambiguity (132 unique values):}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item ``Counterparty'' vs ``Counterparty Bank'' distinction unclear
 \item Compound values indicate multi-party rules needing proper structure
 \item Need hierarchical taxonomy for party relationships
\end{itemize}

\section{Text Field Characteristics}

Text fields in the corpus vary significantly in coverage and length. The \texttt{llm\_description} field, generated offline using Gemini-2.5-Pro, provides substantially richer content than basic description fields. Table~\ref{tab:text-stats} summarizes these characteristics.

\begin{table}[h]
\centering
\begin{tabular}{lrrr}
\toprule
\textbf{Field} & \textbf{Coverage (\%)} & \textbf{Avg Words} & \textbf{Max Words} \\
\midrule
rule\_name & 100.0 & 9.7 & 32 \\
description\_en & 51.3 & 7.0 & 19 \\
description\_de & 51.3 & 5.3 & 18 \\
rule\_description & 95.9 & 23.3 & 193 \\
keywords & 100.0 & 20.7 & 51 \\
llm\_description & 100.0 & 88.9 & 193 \\
\bottomrule
\end{tabular}
\caption{Text field statistics. LLM descriptions provide 4Ã— more content than basic descriptions.}
\label{tab:text-stats}
\end{table}

The rich LLM descriptions (averaging 89 words) provide the semantic context that justifies the 0.80 weight assigned to semantic retrieval in our hybrid scoring.

\section{Keyword Analysis}

Keywords form the foundation of our BM25 retrieval signal. With 100\% coverage, every rule has curated search terms enabling lexical matching.

\subsection{Keyword Distribution}

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item \textbf{Total unique keywords}: 4,239
 \item \textbf{Keywords per rule}: Average 11.6 (median 11, range 5-28)
 \item \textbf{Singleton keywords}: 2,575 (60.7\%)
 \item \textbf{High-frequency keywords}: 237 terms appear in 10+ rules
 \item \textbf{Average keyword length}: 14.2 characters
\end{itemize}

The moderate keyword overlap (39.3\% non-singleton) provides sufficient discriminative power for BM25, justifying its 0.10 weight contribution.

\subsection{Top Keywords by Frequency}

The most frequent keywords reveal the corpus's focus on payment validation and party verification, as shown below.

\vspace{0.5em}
\noindent
\begin{minipage}{\textwidth}
\centering
\begin{tabular}{lrc}
\toprule
\textbf{Keyword} & \textbf{Occurrences} & \textbf{\% of Rules} \\
\midrule
directive & 139 & 12.0 \\
payment instruction & 107 & 9.2 \\
opc & 103 & 8.9 \\
length validation & 100 & 8.6 \\
validation & 95 & 8.2 \\
narr & 92 & 8.0 \\
sort code & 92 & 8.0 \\
counterparty & 90 & 7.8 \\
counterparty account number & 88 & 7.6 \\
orderer & 76 & 6.6 \\
\bottomrule
\end{tabular}
\captionof{table}{Top 10 keywords revealing domain focus on payment validation and party verification.}
\label{tab:top-keywords}
\end{minipage}
\vspace{0.5em}

\section{Embedding Quality Assessment}

The corpus achieves perfect embedding coverage with all 1,157 rules containing valid 1024-dimensional vectors from UAE-Large-V1. These embeddings, generated from the \texttt{llm\_description} field, enable the semantic retrieval that contributes 80\% weight in our hybrid scoring.

\subsection{Embedding Characteristics}

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item \textbf{Coverage}: 100\% (all 1,157 rules have valid embeddings)
 \item \textbf{Dimension}: 1024 components per vector
 \item \textbf{Normalization}: L2-normalized (all vectors satisfy $\|\mathbf{v}\|_2 = 1.0$)
 \item \textbf{Storage}: JSON string format averaging 8.8 KB per embedding
 \item \textbf{Total embedding storage}: 10.2 MB of the 32.21 MB corpus
\end{itemize}

\subsection{Similarity Distribution Analysis}

Table~\ref{tab:similarity-stats} presents the pairwise cosine similarity statistics across all rule embeddings.

\begin{table}[h]
\centering
\begin{tabular}{lc}
\toprule
\textbf{Metric} & \textbf{Cosine Similarity} \\
\midrule
Mean & 0.711 \\
Standard Deviation & 0.061 \\
Minimum & 0.510 \\
25th percentile & 0.670 \\
Median & 0.707 \\
75th percentile & 0.747 \\
95th percentile & 0.817 \\
Maximum & 0.990 \\
\bottomrule
\end{tabular}
\caption{Pairwise cosine similarity statistics showing good discriminative range.}
\label{tab:similarity-stats}
\end{table}

The mean similarity of 0.711 with standard deviation 0.061 provides sufficient discriminative power for semantic retrieval while maintaining domain coherence. This distribution validates our relevance threshold choice of 0.30.

\section{Evaluation Dataset Construction}

From this corpus, a business analyst manually selected 30 query-rule pairs and identified expected relevant rules for each query. The evaluation dataset construction ensured:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Coverage of major rule categories present in the corpus
 \item Representation of frequent business scenarios from actual user queries
 \item Mix of keyword-friendly queries (exact term matches) and semantic-dependent queries (conceptual matches)
 \item Geographic diversity across supported countries
 \item Clear mapping between natural language queries and target rules
\end{itemize}

This manually curated evaluation set, while limited in size, captures real retrieval challenges and enabled tuning of our hybrid weights, resulting in the optimal configuration of 0.80 semantic, 0.10 BM25, and 0.10 fuzzy weights.

\section{Data Quality Assessment}

\subsection{Overall Quality Metrics}

The corpus achieves an overall quality score of \textbf{89.6\%} (Grade B), indicating production readiness with specific areas for improvement. The breakdown by category is shown below.

\vspace{0.5em}
\noindent
\begin{minipage}{\textwidth}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Category} & \textbf{Score (\%)} & \textbf{Weight} & \textbf{Contribution} \\
\midrule
Search Fields & 100.0 & 0.40 & 40.0 \\
Core Identifiers & 100.0 & 0.20 & 20.0 \\
Embeddings & 100.0 & 0.15 & 15.0 \\
Keywords & 100.0 & 0.15 & 15.0 \\
Categorical Tags & 55.6 & 0.10 & 5.6 \\
\midrule
\textbf{Overall} & \textbf{89.6} & \textbf{1.00} & \textbf{95.6} \\
\bottomrule
\end{tabular}
\captionof{table}{Quality score breakdown by category showing tag standardization as the primary gap.}
\label{tab:quality-breakdown}
\end{minipage}
\vspace{0.5em}

\subsection{Prioritized Improvement Roadmap}

Based on impact to retrieval quality and user experience:

\begin{enumerate}[leftmargin=*,itemsep=6pt,topsep=4pt]
 \item \textbf{\textcolor{red}{CRITICAL} â€” Standardize Categorical Tags}
   \begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
     \item Reduce rule types from 177 to 20 standard categories
     \item Apply ISO 3166 country codes consistently  
     \item Define clear business type taxonomy (target: 30 types)
     \item Create hierarchical party agent structure
   \end{itemize}
   
 \item \textbf{\textcolor{orange}{HIGH} â€” Expand Tag Coverage}
   \begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
     \item Increase country tags from 48.7 \% to 75 \%
     \item Expand business type from 36.5 \% to 80 \%
     \item Validate existing tag accuracy through sampling
   \end{itemize}
   
 \item \textbf{\textcolor{yellow!50!black}{MEDIUM} â€” Enhance Multilingual Support}
   \begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
     \item Complete German descriptions (currently 51.3 \%)
     \item Complete English descriptions (currently 51.3 \%)
     \item Ensure consistency between language variants
   \end{itemize}
   
 \item \textbf{\textcolor{green!50!black}{LOW} â€” Complete Optional Fields}
   \begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
     \item BANSTA error codes (currently 51.2 \%)
     \item ISO error codes (currently 50.0 \%)
     \item Additional metadata for audit trails
   \end{itemize}
\end{enumerate}

\section{Summary}

The corpus analysis reveals a high-quality dataset well-positioned for production deployment with targeted improvements needed in tag standardization.

\textbf{Core Strengths:}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item Perfect coverage (100\%) in all search-critical fields enabling effective hybrid retrieval
 \item 4,239 unique keywords supporting BM25 retrieval (10\% hybrid weight)
 \item Complete L2-normalized embeddings with good discriminative properties for semantic search (80\% hybrid weight)
 \item Rich LLM-generated descriptions averaging 89 words providing comprehensive semantic context
 \item Full rule implementation code for all 1,157 rules
 \item Sufficient similarity distribution (mean 0.711, std 0.061) validating our 0.30 relevance threshold
 \item Manually curated evaluation dataset with business analyst validation
\end{itemize}

\textbf{Priority Improvements:}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
 \item \textbf{Tag standardization}: Reduce fragmentation from 177 rule types and 128 business types to manageable taxonomies
 \item \textbf{Tag coverage}: Expand business type (36.5\%) and country (48.7\%) coverage to improve filtering
 \item \textbf{Tag accuracy}: Audit and correct existing categorical assignments
 \item \textbf{Multilingual completeness}: Fill gaps in German and English descriptions
\end{itemize}

With an overall quality grade of B (89.6\%), the corpus exceeds minimum requirements for production deployment. The standardization effort successfully transformed distributed, inconsistent rule data into a unified, searchable knowledge base. The immediate priority should focus on categorical tag standardization, as this directly impacts retrieval precision and user experience through faceted filtering.
