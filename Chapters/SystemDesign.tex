\chapter{System Design}
\label{ch:system-design}

This chapter presents the architectural design of our hybrid retrieval system for validation rules, detailing how we achieve sub-second semantic search within banking infrastructure constraints through a deliberately simple monolithic architecture.

\section{Architectural Overview}

\subsection{Design Philosophy}

The system implements a monolithic architecture where all components operate within a single Python process. This design choice, initially driven by deployment constraints, proved optimal for our use case by eliminating network overhead, simplifying debugging, and ensuring deterministic behavior required for audit compliance.

The architecture comprises three logical layers:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item \textbf{Presentation Layer}: Dash web interface with search and chat components
  \item \textbf{Business Logic Layer}: Hybrid retrieval engine with three scoring signals
  \item \textbf{Data Layer}: CSV corpus with SQLite caching and in-memory indices
\end{itemize}

All layers execute within the same process, communicating through direct function calls rather than network protocols.

\subsection{Core Components}

The system consists of five major components that work together to provide rule retrieval:

\begin{enumerate}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item \textbf{RuleRetriever}: Orchestrates hybrid search by combining semantic, BM25, and fuzzy signals
  \item \textbf{EmbeddingManager}: Manages UAE-Large-V1 model for semantic similarity computation
  \item \textbf{EmbeddingIndex}: Maintains pre-computed embeddings and performs cosine similarity search
  \item \textbf{DatabaseManager}: Handles SQLite operations for filtering and metadata
  \item \textbf{RuleDataLoader}: Normalizes CSV data into memory-efficient structures
\end{enumerate}

\section{Data Flow Architecture}

\subsection{Initialization Sequence}

At startup, the system executes a deterministic initialization pipeline:

\begin{enumerate}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Load CSV corpus (32.21MB) using pandas
  \item Validate schema and field presence
  \item Parse JSON-encoded embeddings to NumPy arrays
  \item Build SQLite database for filtering
  \item Construct BM25 index from keywords field
  \item Initialize embedding index with pre-computed vectors
  \item Start Dash web server
\end{enumerate}

Total initialization time: 464ms for 1,157 rules.

\subsection{Query Processing Pipeline}

When a user submits a search query, the system follows this processing flow:

\begin{enumerate}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item \textbf{Filter Application}: Reduce candidate set based on categorical selections
  \item \textbf{Parallel Signal Computation}:
     \begin{itemize}
       \item Semantic: Cosine similarity via embedding dot product (2.4ms)
       \item BM25: Probabilistic retrieval over keywords (1.2ms)
       \item Fuzzy: String similarity on rule names (19.4ms)
     \end{itemize}
  \item \textbf{Score Normalization}: Max-normalize each signal to [0,1]
  \item \textbf{Weighted Fusion}: Combine with weights (0.80, 0.10, 0.10)
  \item \textbf{Threshold Application}: Filter results below τ=0.30
  \item \textbf{Ranking}: Sort by combined score
  \item \textbf{Result Assembly}: Enrich with metadata and return top-k
\end{enumerate}

\section{Component Design}

\subsection{Retrieval Engine}

The retrieval engine implements three complementary scoring mechanisms:

\textbf{Semantic Signal (80\% weight):}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Pre-computed 1024-dimensional UAE-Large-V1 embeddings
  \item Cosine similarity through normalized dot product
  \item Captures conceptual similarity beyond keywords
\end{itemize}

\textbf{BM25 Signal (10\% weight):}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Probabilistic retrieval over curated keywords field
  \item Handles exact terminology matches
  \item Built using rank-bm25 library with default parameters
\end{itemize}

\textbf{Fuzzy Signal (10\% weight):}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Partial ratio matching on rule names
  \item No pre-built index (computed at query time)
  \item Catches misspellings and partial matches
\end{itemize}

\subsection{Data Management}

The system uses a three-tier data architecture:

\textbf{Persistent Storage:}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item CSV file (32.21MB) containing all rule data
  \item Embeddings stored as JSON strings for portability
  \item Version controlled in Git for audit trail
\end{itemize}

\textbf{Runtime Caches:}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item SQLite database for filtering operations
  \item NumPy array (1157×1024) for embedding matrix
  \item BM25 inverted index in memory
\end{itemize}

\textbf{Memory Profile:}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Embeddings: 4.7MB (float32 precision)
  \item BM25 index: 45MB
  \item Rule metadata: 15MB
  \item Total: 530MB including Dash framework
\end{itemize}

\subsection{User Interface}

The Dash-based interface provides two primary interaction modes:

\textbf{Search Interface:}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Natural language query input
  \item Faceted filtering (Rule Type, Country, Business Type, Party Agent)
  \item Mode selection (Hybrid vs Keyword-only)
  \item Ranked results with similarity scores
  \item Detailed rule view with code display
\end{itemize}

\textbf{Chat Interface:}
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Conversational rule exploration
  \item Drag-and-drop rule context
  \item Template-based explanation generation
  \item Session state management
\end{itemize}

\section{Performance Optimizations}

\subsection{Startup Optimizations}

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Parallel index construction using ThreadPoolExecutor
  \item Lazy parsing of JSON embeddings
  \item Pre-allocated NumPy arrays
  \item SQLite WAL mode for concurrent access
\end{itemize}

\subsection{Query-Time Optimizations}

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Vectorized cosine similarity computation
  \item Partial sorting with np.argpartition for top-k
  \item Early termination when minimum score not met
  \item Shared memory access without copying
\end{itemize}

\section{Security and Compliance}

\subsection{Security Measures}

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Input sanitization prevents injection attacks
  \item Read-only operations on all data
  \item No external API calls or network dependencies
  \item File-based storage with OS-level permissions
\end{itemize}

\subsection{Audit Compliance}

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Deterministic scoring ensures reproducible results
  \item Complete query logging with timestamps
  \item Version-controlled corpus in Git
  \item Transparent score computation with component breakdowns
\end{itemize}

\section{Design Trade-offs}

\subsection{Choices Made}

\begin{table}[!ht]
\centering
\begin{tabular}{p{3.5cm}p{7.5cm}}
\toprule
\textbf{Design Choice} & \textbf{Rationale} \\
\midrule
Monolithic architecture & Eliminates network overhead, simplifies deployment \\
CSV storage & Enables version control and manual inspection \\
JSON embeddings & Maintains portability while allowing single-file deployment \\
In-memory indices & Avoids synchronization complexity, ensures fast access \\
Brute-force search & More reliable than approximate methods at our scale \\
Fixed weights & Simplifies system while maintaining good performance \\
\bottomrule
\end{tabular}
\caption{Key design decisions and their justifications.}
\label{tab:design-choices}
\end{table}

\subsection{Rejected Alternatives}

We explicitly rejected several common approaches:

\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item \textbf{Microservices}: Unnecessary complexity for our scale
  \item \textbf{FAISS}: Complexity not justified for ~1000 rules; brute-force is faster at this scale
  \item \textbf{External vector database}: Introduces dependencies and latency
  \item \textbf{Query-time LLM}: Non-deterministic and slow
  \item \textbf{Binary embedding format}: Loses version control benefits
\end{itemize}

\section{Scalability Considerations}

\subsection{Current Limits}

The design accommodates:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Up to 10,000 rules before performance degradation
  \item 10-20 concurrent users per instance
  \item Daily corpus updates via restart
  \item 2GB maximum memory footprint
\end{itemize}

\subsection{Scaling Strategies}

When limits are reached:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Horizontal scaling: Multiple instances behind load balancer
  \item Sharding: Split corpus by business domain
  \item Caching: Add Redis for frequent queries
  \item Approximate search: Implement LSH for larger corpora
\end{itemize}

\section{Summary}

The system design prioritizes simplicity and reliability over architectural complexity. By implementing hybrid retrieval within a monolithic Python application, we achieve production-ready performance (58ms median latency) while maintaining the auditability and determinism required for banking deployment.

Key design principles:
\begin{itemize}[leftmargin=*,itemsep=2pt,topsep=2pt]
  \item Offline complexity, online simplicity
  \item Memory-resident indices for predictable performance
  \item Standard libraries over specialized tools
  \item Transparent scoring for regulatory compliance
\end{itemize}

This architecture proves that sophisticated information retrieval capabilities can be delivered through thoughtful engineering within real-world constraints, without requiring distributed systems or specialized infrastructure.
